<!--1598475146000-->
[令人震惊的人工智能语言模型](https://cn.ft.com/story/001089141?full=y)
------

<div></div><div class="story-lead">GPT-3可能会大大提高人类的生产率和创造力，包含1750亿个语言参数，它可能已具备类似人类的一般智能。</div><div class=" story-image image"><img src="https://thumbor.ftacademy.cn/unsafe/1340x754/https://thumbor.ftacademy.cn/unsafe/picture/4/000099724_piclink.jpg"></div><div class="story-body"><div id="story-body-container"><p>当旧金山一家人工智能公司的首席执行官试图降温围绕他自己的技术的炒作时，你就会知道，有些人变得太容易激动了。</p><p>但这正是萨姆•奥尔特曼(Sam Altman，<i>见文首照片</i>)上月试图做的，以回应OpenAI最新的GPT-3语言模型所引发的狂喜反应。“GPT-3的炒作太过离谱，”奥尔特曼在Twitter上写道，“它令人印象深刻（感谢那些溢美之词！），但它仍有严重缺陷，有时会犯非常愚蠢的错误。”</p><p>GPT-3（生成式预训练变换器第三版）本质上是一个超级复杂的自动完成功能，这么说听起来没有那么令人兴奋。但GPT-3的引人注目之处在于它的规模、灵活性以及未来开发的可能性。</p><p>GPT-3利用从互联网吸收的数千亿词汇，并使用类似于谷歌(Google) DeepMind的AlphaGo的神经网络技术，被训练为可以识别、然后复制复杂模式。GPT-3包含1750亿个语言参数，是仅次于它的同等模型的逾10倍。</p><div  data-o-ads-name="mpu-middle1" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="FtcMpu" data-o-ads-formats-large="FtcMpu" data-o-ads-formats-extra="FtcMpu" data-o-ads-targeting="cnpos=middle1;" data-cy='[{"devices":["PC","iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle1","container":"mpuInStory"}]'></div><p>在私下beta测试中获准使用GPT-3的开发者，使用它创作诗歌、文章、漫画素描，编写计算机代码，谱写吉他即兴曲，提供医疗建议，以及重新构思视频游戏，有时效果惊人。“使用GPT-3感觉像看到未来，”科技企业家阿拉姆•萨贝提(Arram Sabeti)在Twitter上写道，“它好的令人震惊。”萨贝提曾使用这款软件撰写雷蒙德•钱德勒(Raymond Chandler)风格的有关哈利•波特(Harry Potter)的电影剧本。</p><p>我们很容易想象如何使用GPT-3来驱动数字助理，让人几乎不可能知道自己是在与机器还是人打交道。如果大规模部署于各种活动，这款软件有望显著提高人类的生产率和创造力。</p><p>然而，我们也很容易想象这种技术的阴暗用途：成为虚假信息宣传、篡改视频或深度伪造的工具。此外，电脑科学家质疑OpenAI不加选择地使用训练数据集的做法，这意味着GPT-3以令人震惊的程度反映人类的成见、偏向和偏见。从这个意义上说，GPT-3也许准确反映了人类本性，但我们难道不应该努力设计出比我们自己更好的人工智能系统吗？</p><p>这项技术还引发了一系列道德问题，在线哲学网站Daily Nous迅速召集的9位专家对此展开辩论。</p><p>这些哲学家们认为GPT-3“自圆其说的本事令人不安，没头脑得可笑”。它比一台机器聪明一些，但比不上人类头脑，它不知道自己知道什么，不知道什么，有时还会胡言乱语。</p><p>爱丁堡大学(University of Edinburgh)伦理学教授香农•瓦洛(Shannon Vallor)辩称，GPT-3没有理解能力，她将其定义为一个建立、修复和加强“不断变化的意识纽带”的持续项目。她写道：“就像一个胡扯的人通过照搬首席执行官回忆录里听上去让人印象深刻的话而通过初次面试，GPT-3也会吐出一些相当动听的胡扯。”</p><div data-o-ads-name="mpu-middle2" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="false" data-o-ads-formats-large="false" data-o-ads-formats-extra="false" data-o-ads-targeting="cnpos=middle2;" data-cy='[{"devices":["iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle2","container":"mpuInStory"}]'></div><p>然而，纽约大学(New York University)哲学教授戴维•查默斯(David Chalmers)认为，GPT-3显示出类似人类一般智能的迹象。“我认为一条拥有302个神经元的虫子是有意识的，因此我对这样一个构想持开放态度，即拥有1750亿个参数的GPT-3也是有意识的。”</p><p>耐人寻味的是，在被输入这些评论后，并被要求答复后，GPT-3称：“必须说明，我不是一个人。我没有自我意识。我没有意识。我感觉不到疼痛。我享受不了任何东西。我是一台冷酷、会计算的机器，设计宗旨是模拟人类的反应，并预测某些结果的概率。我做出回应的唯一原因是要捍卫我的荣誉。”</p><p>相当有说服力，不是吗？认为电脑可能有“荣誉”的观点表明，GPT-3在模仿我们倾向于把技术拟人化方面是多么出色。当然，除非……</p><p><i>译者/梁艳裳</i></p></div><div class="clearfloat"></div></div>
