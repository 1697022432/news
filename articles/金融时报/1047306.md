<!--1600894380000-->
[用合成数据打造“数字天堂”](https://cn.ft.com/story/001089541?full=y)
------

<div></div><div class="story-lead">阿胡贾：有这样一个乌托邦愿景：反映理想世界的合成数据被用来磨砺公正的算法，在这样的数字天堂，数据仍然为王，但它至少是仁慈的君主。</div><div class=" story-image image"><img src="https://thumbor.ftacademy.cn/unsafe/1340x754/https://thumbor.ftacademy.cn/unsafe/picture/5/000088365_piclink.jpg"></div><div class="story-body"><div id="story-body-container"><p>在一个以数据为王的算法驱动的世界里，一个失误可能导致一场大混乱。Netflix在2009年发布由订户撰写的匿名电影评论时发现了这一点。通过将那些简短评论与另一个网站上的评论进行交叉比对，数据侦探发现他们可以识别个人订户和他们在看的内容。一名同性恋客户起诉该公司侵犯隐私；Netflix与其达成了和解。</p><p>这一事件仍被寻求在不暴露提供信息的个人的情况下从数据中筛选有用信息的学者们引用。在匿名化处理失败的地方，合成数据可能会成功。</p><p>顾名思义，合成数据是人工生成的。它通常是通过加噪算法，将真实世界的数据汇集起来构建一个新的数据集而产生的。由此产生的数据集捕获原始信息的统计特征，而不是变成一件暴露信息来源的复制品。它的有用性取决于一个被称为差分隐私的原则：任何挖掘合成数据的人，都可以像他们从真实数据中那样，得出同样的统计推断，但无法识别贡献信息的个人。</p><p>伦敦大学学院(University College London)的艾米利亚诺•德克里斯托法罗(Emiliano De Cristofaro)对合成数据从严密保管的数据库中获取有用信息的潜力感到兴奋。例如，揭露欺诈可能具有挑战性，因为法规限制了信息共享的方式，甚至在银行内部也是如此。合成数据可以帮助揭示有用的模式，同时掩盖个别事件。</p><div  data-o-ads-name="mpu-middle1" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="FtcMpu" data-o-ads-formats-large="FtcMpu" data-o-ads-formats-extra="FtcMpu" data-o-ads-targeting="cnpos=middle1;" data-cy='[{"devices":["PC","iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle1","container":"mpuInStory"}]'></div><p>他说：“如果你试图训练一种算法来检测欺诈，你不会在意具体交易以及谁做了这些交易。你关心的是统计数据，比如金额是否刚好低于触发审计所需的门槛，或者倾向于在接近季度末时发生。”就像从原始数据一样，这类数字可以从合成数据中提取出来。</p><p>合成数据的想法最早是在20世纪90年代提出的，但是机器学习和计算能力的提高，加上数据管理方面的法规更加严格，使其成为一项值得关注的技术。伦敦大学学院的衍生企业Hazy在2018年赢得了100万美元的微软创新人工智能(Microsoft  Innovate.AI)投资奖；同年，美国国家标准与技术研究院(National Institute of Standards and Technology)将差分隐私和合成数据列为一项公开挑战的重点。去年，英国国家统计署(ONS)的一份报告称，这种技术为“政府、学术界和私营部门之间共享数据提供了一种更安全、更简便、更快捷的方式”。</p><p>数据并不一定要植根于现实世界才能有价值：它可以被炮制出来，植入一些缺失或难以获取数据的地方。善于动脑筋的研究人员一直在为视频游戏创建的虚拟道路上测试无人驾驶汽车软件。</p><p>当然，合成数据可能被框定为“假数据”——但在某些情况下，这是意外收获。接受真实世界信息培训的人工智能，会有一种固有的偏见：在刑事司法和信用评分等领域，算法决策显示出种族歧视的证据。这种现象被记录在鲁哈•本杰明(Ruha Benjamin)的《科技背后的种族》(Race after Technology)等书中，该书将这种编码偏见与当年为美国南部种族隔离创造条件的吉姆•克劳法(Jim Crow laws)相提并论。</p><p>华盛顿大学(Washington University)数据科学家比尔•豪(Bill Howe)认为，人工智能不应助长这种歧视。他认为合成数据可以帮助解决复杂的社会问题，比如贫困：“我们可以改变这种偏见。人们可以发布反映我们想要的世界的合成数据。为什么不把它们用作人工智能的训练数据集呢？”他说道。</p><p>这是一个乌托邦式的惊人愿景：数据不是假的，而是理想化的，用于在数字天堂中磨砺完美公正和公平的算法，在这个数字天堂里，数据仍然为王，但它是仁慈的君主，而不是有偏见的族长。</p><div data-o-ads-name="mpu-middle2" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="false" data-o-ads-formats-large="false" data-o-ads-formats-extra="false" data-o-ads-targeting="cnpos=middle2;" data-cy='[{"devices":["iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle2","container":"mpuInStory"}]'></div><p><i>本文作者是科学评论员</i></p><p>译者/裴伴</p></div><div class="clearfloat"></div></div>
