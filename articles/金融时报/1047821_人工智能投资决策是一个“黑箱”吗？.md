<!--1596570734000-->
[人工智能投资决策是一个“黑箱”吗？](https://cn.ft.com/story/001088828?full=y)
------

<div></div><div class="story-lead">柴志杰、李偲：AI决策在众多行业中面临同一个窘境，就是怎样“取信于人”，即人类始终无法完全搞懂AI是如何作决策的，甚至开发者本身也一样。</div><div class=" story-image image"><img src="https://thumbor.ftacademy.cn/unsafe/1340x754/https://thumbor.ftacademy.cn/unsafe/picture/8/000089708_piclink.jpg"></div><div class="story-body"><div id="story-body-container"><p>当前人工智能的应用发展一日千里，在医疗健康、制造业、零售业、城市管理等众多领域，人类已越来越多地让AI来帮我们分析和决策。在金融投资领域，我们同样也看到运用人工智能技术的产品脱颖而出，尤其在今年上半年新冠疫情引发的全球市场波动中，不少AI量化基金走势稳健，稳定性远超传统基金产品。</p><p>然而，AI决策在众多行业中依然面临着一个窘境，就是怎样“取信于人”——人类始终无法完全搞懂AI是如何作决策的，甚至开发者本身也一样。在金融投资中，传统投资的大师们强调，不要投资于不懂的东西，AI这种“不可言说”的投资策略，给许多投资者带来强烈的不安全感。</p><p>也因此，AI尤其机器学习决策被称为“黑箱模型”（Black Box Models）。但即便这个比喻也不太恰当——“黑箱”，意味着箱子打开以后，其运作原理是人们看得懂的，但人工智能即便“打开”它的决策过程和结果，或许仍然不能让人类看懂。</p><p><b>人类投资者无法理解的因子</b></p><div  data-o-ads-name="mpu-middle1" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="FtcMpu" data-o-ads-formats-large="FtcMpu" data-o-ads-formats-extra="FtcMpu" data-o-ads-targeting="cnpos=middle1;" data-cy='[{"devices":["PC","iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle1","container":"mpuInStory"}]'></div><p>2016年，谷歌开发的人工智能系统AlphaGo与韩国职业九段棋手李世石的历史性对弈中，AlphaGo在第二局第37手下出了被视为扭转战局的一步，欧洲围棋冠军樊麾当时的评价是：“这不是人类的棋步。”（It’s not a human move.）</p><p>自那时起，人工智能在众多领域，开始探索人脑思维能力从未涉足的秘境。例如当前AI投资中一个热门方向，是利用深度学习技术挖掘令股票回报更佳的“因子”，如波动性、价值等。顶尖的AI基金通常宣称模型至少有数百个因子，并且能够实时衡量数百个因子之间的动态关系和权重变化，看起来似乎已极端复杂，但事实上人工智能模型真正做的还远不止于此——除了人类投资者能够理解的因子外，AI机器学习模型在对市场数据的深度学习过程中还会挖掘出大量完全不能用人类语言和逻辑解释的因子。</p><p>在我们的模型中，这些因子呈现为一个极冗长的数学表达式，其复杂程度连模型开发人员也无法看懂，我们将它们称为“深度因子”。由于它们的逻辑和表达过于复杂，在人类现有的经济学体系中显然看不出任何意义，即便最优秀的数学家也难以分析。然而，我们从反复的测试中可以看到这些“深度因子”不但有很强的统计学意义，对市场趋势有强大的预测力，甚至放到不同地区市场的测试中，依然能够明显地增加回报。</p><p>同时，它们与已知的数百个传统因子相关性非常低，这显示它们是在独立地发挥作用，换言之，这些深度因子跟价值、波动性、成长性这些人类投资者熟悉的因子一样，都是市场中真实存在的关联，只是以人脑当前的思维水平，既不能找到，也无法读懂这些关联。</p><p>人类必须承认的一个客观事实是，人脑理解的能力相当有限，我们无法理解宇宙的层次，甚至对我们自己的大脑如何运作也所知甚少。物理学家霍金曾经提出一个“M理论”，认为宇宙存在11个维度，而人类能够理解到的仅有4个（三维空间加上时间）。人工智能深度学习的运行，动辄涉及几百万乃至数十亿的参数，即便将全部算法和表达式摊开在眼前，人类能够理解的依然有限。</p><p><b>可解释的人工智能</b></p><div data-o-ads-name="mpu-middle2" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="false" data-o-ads-formats-large="false" data-o-ads-formats-extra="false" data-o-ads-targeting="cnpos=middle2;" data-cy='[{"devices":["iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle2","container":"mpuInStory"}]'></div><p>既然人工智能对于人脑智能犹如“降维打击”，我们是否就不去尝试解释了呢？</p><p>当然并非如此，假如人工智能在发展中一直不能够解释，人类将无法驾驭人工智能的决策，那么人工智能就不可能实现与人类协同工作。更大的问题是，如果人类没有解读人工智能的能力，一旦其决策出现了错误，或是出现干扰、虚假的信息，在投资领域可能带来重大亏损，在医疗、交通和国家安全等领域后果则显然更具破坏性。</p><p>人类不能直接看懂AI复杂的逻辑，不代表我们不能够用人类可以理解的方式去分析，在我们开发人工智能投资机器学习模型过程中，对于模型异常情况的检测和纠错就是一个例子。开发人员会从更精细的角度，孤立分离出机器学习过程中的每一个市场数据中提取出来的“特征”（Features），计算出每一个特征对于最终决策的贡献比重，从而推断出异常的原因。这种算法称为“孤立森林”（Isolation Trees），是对于异常检测的一种相当高效的方法。</p><p>除了具体到特征的分析，我们也会使用针对模型结构改善的算法。运用分拆法可将神经网络模型一层一层拆开，并输入随机数据来检测每一层模型的输出情况，或是剥离某些层次后的输出情况，找到异常的层次后，再进一步分拆到每一个节点（神经元），通过其分布状况和对于模型选股最终决策的贡献比重，来定位存在异常的节点。</p><p>事实上，近年来“可解释的人工智能”（Explainable Artificial Intelligence,简称XAI）逐渐成为人工智能中一个新兴方向，聚焦于探究人工智能可为人类所理解的功能或运作机制，令其拥有足够的透明度。这一方向在过去五年中发展极快，也获得了越来越高的关注。</p><div data-o-ads-name="mpu-middle3" class="o-ads in-article-advert" data-o-ads-formats-default="false"  data-o-ads-formats-small="FtcMobileMpu"  data-o-ads-formats-medium="false" data-o-ads-formats-large="false" data-o-ads-formats-extra="false" data-o-ads-targeting="cnpos=middle3;" data-cy='[{"devices":["iPhoneWeb","AndroidWeb","iPhoneApp","AndroidApp"],"pattern":"MPU","position":"Middle3","container":"mpuInStory"}]'></div><p>2018年，欧盟首先将人工智能的可解释性提升到法律层面，当年5月发布的资料保护规范（General Data Protection Regulation）中，提出对于“自动化的决策”（包括AI的决策）用户有拒绝适用，以及要求解释的权利。美国随后在其“算法问责法案2019”（Algorithmic Accountability Act of 2019）之中，也赋予用户同样的权利，亚洲如新加坡等地，也颁布了类似的法规，成为研究机构投入XAI的重要推动力。</p><p>XAI发展到今天，已开发出了诸多有效的算法，可以说人工智能“黑盒”正在慢慢打开，目前打开的进度接近一半。随着电脑算力继续快速提升，相信在不远的未来，我们将能够打开人工智能黑盒中的全部秘密。</p><p>到那时，由AI投资平台重新提取和归纳的投资策略，或许会反过来重塑每个投资者心目中对股票的定义。同样的情况还会发生在各个领域，推动人类整体认知水平上一次质的飞跃。作为人类前所未有的强大思维工具，人工智能除了在我们生活的中的方方面面提供更多的高效和便利之外，或许更将成为人类解答宇宙和生命终极奥秘的重要武器。</p><p>（作者介绍：柴志杰系中国平安资产管理（香港）资本市场负责人、首席投资官；李偲博士系中国平安资产管理（香港）人工智能量化投资高级经理。本文仅代表作者观点。责任编辑邮箱：Tao.feng@ftchinese.com）</p></div><div class="clearfloat"></div></div>
